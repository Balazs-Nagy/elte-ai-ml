{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Growing random graph model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Click on the title and rename the file  with your name! </b>\n",
    "\n",
    "In this homework you will implement a growing random graph model and test how fast its degree distribution converges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GrowingRandomGraphs(N, gamma, M):\n",
    "    \"\"\"This function outputs a graph on N vertices that is generated as follows. It starts with a single vertex 0. \n",
    "    Then having a graph G_k on vertices 0,1,...,k-1 we add a new vertex k and for each i in {0,1,..,k-1} connect k and i with \n",
    "    probability min(1,((degree_{G_k}(i)+1)/(2e(G_k)+k))^(gamma)).\"\"\"\n",
    "\n",
    "    # It starts with a single vertex 0.\n",
    "    G = Graph()\n",
    "    G.add_vertices([0])\n",
    "\n",
    "    edges = []\n",
    "    #probs = {}\n",
    "    for k in range(1, N):\n",
    "        #prob = []\n",
    "        # degrees of G on k-1 vertices\n",
    "        d_Gk = dict(zip(G.vertices(), G.degree()))\n",
    "        # number of edges of G on k-1 vertices\n",
    "        e_Gk = len(G.edges())\n",
    "        # draw an edge using the probability function\n",
    "        for i in G.vertices():\n",
    "            p = min(1, M*((1+d_Gk.get(i, 0))/(2*e_Gk+k))**gamma)\n",
    "            if p >= np.random.rand():\n",
    "                edges.append((k, i, p))\n",
    "            #prob.append(float(p))\n",
    "        #probs[k] = prob\n",
    "        # add vertex k and the created edges\n",
    "        G.add_vertices([k])\n",
    "        G.add_edges(edges)\n",
    "    return G #, probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$p = \\min (1, M \\left(\\frac{d_{G_{k}}(i)+1}{2e_{G_k}+k}\\right)^{\\gamma})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next you have to define the degree distribution and the total variation of the probability distribution. The degree distribution is practically the same as the degree histogram, only you have to divide each element with the number of vertices to get a probability distribution. The total variation of probability distributions P and Q is defined as\n",
    "$$d_{\\mathrm{TV}}(P,Q)=\\frac{1}{2}\\sum_{i=1}^{\\infty}|P(i)-Q(i)|.$$\n",
    "P and Q are given as lists, if they are not of the same length, then add $0$'s to the shorter list to make them to be of the same length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DegreeDistribution(G):\n",
    "    \"\"\"It outputs a list P such that P[i] is the probability that a random vertex (chosen uniformly) has degree i.\"\"\"\n",
    "    # G.degree_histogram() returns a list, whose i-th entry is the frequency of degree i\n",
    "    # which we normalise with the number of vertices G.order() in order to get the degree distribution\n",
    "    return np.array(G.degree_histogram()) / G.order()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TotalVariation(P,Q):\n",
    "    \"\"\"It outputs the total variation of the probability distribution P and Q.\"\"\"\n",
    "    # numpy arrays are very convenient for this\n",
    "    # pad zeros to P if necessary\n",
    "    pad = max(len(Q)-len(P), 0)\n",
    "    P = np.pad(np.array(P), (0, pad), 'constant', constant_values=(0, 0))\n",
    "    # pad zeros to Q if necessary\n",
    "    pad = max(len(P)-len(Q), 0)\n",
    "    Q = np.pad(np.array(Q), (0, pad), 'constant', constant_values=(0, 0))    \n",
    "    # calculate total variation based on formula\n",
    "    return np.sum(np.abs(P-Q))/2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Later you will also need an induced subgraph to compare two moments of the same graph process. More precisely you will compare the final graph with an intermediate graph. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def InducedSubgraph(G,n):\n",
    "    \"\"\"Given a graph G on N vertices it outputs the graph induced on vertices 0,1,..n-1 for $n< N$.\"\"\"\n",
    "    return G.subgraph(range(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p1:\n",
      "[0.094 0.182 0.176 0.141 0.123 0.074 0.054 0.035 0.024 0.021 0.011 0.007\n",
      " 0.009 0.004 0.008 0.009 0.006 0.002 0.001 0.001 0.001 0.    0.003 0.\n",
      " 0.002 0.003 0.002 0.    0.    0.    0.001 0.001 0.001 0.    0.001 0.\n",
      " 0.    0.    0.001 0.    0.    0.    0.    0.    0.001 0.    0.    0.\n",
      " 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.001]\n",
      "\n",
      "p2:\n",
      "[0.097 0.173 0.19  0.145 0.112 0.063 0.054 0.035 0.032 0.015 0.011 0.019\n",
      " 0.015 0.008 0.004 0.003 0.002 0.002 0.002 0.004 0.003 0.002 0.    0.\n",
      " 0.    0.    0.001 0.001 0.001 0.    0.    0.001 0.    0.    0.    0.\n",
      " 0.001 0.    0.001 0.002 0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.001]\n",
      "\n",
      "q1:\n",
      "[0.13 0.12 0.15 0.1  0.15 0.13 0.04 0.03 0.02 0.05 0.   0.01 0.03 0.01\n",
      " 0.   0.02 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      " 0.   0.01]\n",
      "\n",
      "TotalVariation(p1,p2)=\n",
      "0.06500000000000002\n",
      "\n",
      "TotalVariation(p1,q1)=\n",
      "0.199\n"
     ]
    }
   ],
   "source": [
    "G1=GrowingRandomGraphs(N=1000, gamma=1, M=2)\n",
    "G2=GrowingRandomGraphs(N=1000, gamma=1, M=2)\n",
    "H=InducedSubgraph(G1, n=100)\n",
    "p1=DegreeDistribution(G1)\n",
    "p2=DegreeDistribution(G2)\n",
    "q1=DegreeDistribution(H)\n",
    "print(f'p1:\\n{p1}')\n",
    "print(f'\\np2:\\n{p2}')\n",
    "print(f'\\nq1:\\n{q1}')\n",
    "print(f'\\nTotalVariation(p1,p2)=\\n{TotalVariation(p1,p2)}') #Total variation of the degree distibutions of two different copies.\n",
    "print(f'\\nTotalVariation(p1,q1)=\\n{TotalVariation(p1,q1)}')  #Total variation of the degree distrbutions of a graph and a section of it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p1:\n",
      "[0.975 0.019 0.005 0.    0.    0.    0.    0.001]\n",
      "\n",
      "p2:\n",
      "[0.975 0.018 0.004 0.001 0.    0.001 0.    0.    0.001]\n",
      "\n",
      "q1:\n",
      "[0.85 0.11 0.03 0.   0.   0.   0.   0.01]\n",
      "\n",
      "TotalVariation(p1,p2)=\n",
      "0.0030000000000000005\n",
      "\n",
      "TotalVariation(p1,q1)=\n",
      "0.125\n"
     ]
    }
   ],
   "source": [
    "G1=GrowingRandomGraphs(N=1000, gamma=2, M=2)\n",
    "G2=GrowingRandomGraphs(N=1000, gamma=2, M=2)\n",
    "H=InducedSubgraph(G1, n=100)\n",
    "p1=DegreeDistribution(G1)\n",
    "p2=DegreeDistribution(G2)\n",
    "q1=DegreeDistribution(H)\n",
    "print(f'p1:\\n{p1}')\n",
    "print(f'\\np2:\\n{p2}')\n",
    "print(f'\\nq1:\\n{q1}')\n",
    "print(f'\\nTotalVariation(p1,p2)=\\n{TotalVariation(p1,p2)}') #Total variation of the degree distibutions of two different copies.\n",
    "print(f'\\nTotalVariation(p1,q1)=\\n{TotalVariation(p1,q1)}')  #Total variation of the degree distrbutions of a graph and a section of it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p1:\n",
      "[0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.    0.    0.    0.    0.001 0.    0.    0.001\n",
      " 0.001 0.001 0.003 0.003 0.003 0.004 0.01  0.015 0.009 0.009 0.007 0.011\n",
      " 0.021 0.014 0.018 0.021 0.02  0.022 0.025 0.028 0.032 0.022 0.02  0.03\n",
      " 0.025 0.024 0.025 0.029 0.028 0.014 0.024 0.018 0.021 0.014 0.014 0.019\n",
      " 0.019 0.014 0.011 0.017 0.018 0.021 0.011 0.014 0.009 0.013 0.006 0.011\n",
      " 0.007 0.008 0.009 0.008 0.012 0.014 0.008 0.009 0.007 0.006 0.01  0.005\n",
      " 0.006 0.006 0.004 0.008 0.004 0.005 0.002 0.009 0.006 0.005 0.002 0.005\n",
      " 0.002 0.002 0.005 0.005 0.006 0.002 0.002 0.002 0.002 0.005 0.001 0.001\n",
      " 0.002 0.002 0.002 0.    0.    0.001 0.001 0.001 0.001 0.003 0.001 0.003\n",
      " 0.    0.001 0.    0.001 0.    0.    0.001 0.    0.    0.    0.001 0.\n",
      " 0.    0.001 0.    0.    0.001 0.002 0.001 0.001 0.001 0.    0.    0.\n",
      " 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.001 0.    0.    0.    0.    0.    0.001]\n",
      "\n",
      "p2:\n",
      "[0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.    0.    0.    0.001 0.001 0.001 0.001 0.003\n",
      " 0.002 0.005 0.001 0.002 0.005 0.004 0.008 0.003 0.008 0.012 0.012 0.014\n",
      " 0.017 0.014 0.021 0.023 0.023 0.019 0.03  0.02  0.024 0.026 0.032 0.023\n",
      " 0.013 0.031 0.018 0.017 0.022 0.023 0.013 0.023 0.016 0.015 0.021 0.02\n",
      " 0.012 0.015 0.018 0.015 0.01  0.017 0.012 0.013 0.014 0.011 0.014 0.012\n",
      " 0.015 0.009 0.015 0.011 0.006 0.007 0.008 0.008 0.009 0.004 0.008 0.008\n",
      " 0.01  0.005 0.006 0.007 0.007 0.003 0.006 0.005 0.007 0.004 0.006 0.006\n",
      " 0.004 0.006 0.006 0.006 0.004 0.001 0.003 0.001 0.001 0.002 0.003 0.002\n",
      " 0.001 0.002 0.002 0.002 0.002 0.    0.    0.    0.001 0.001 0.    0.003\n",
      " 0.003 0.    0.    0.002 0.    0.    0.    0.    0.    0.001 0.001 0.\n",
      " 0.    0.    0.002 0.001 0.    0.    0.001 0.001 0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.001 0.\n",
      " 0.001 0.    0.    0.    0.    0.    0.    0.001 0.    0.    0.001 0.\n",
      " 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.001]\n",
      "\n",
      "q1:\n",
      "[0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.01 0.   0.\n",
      " 0.02 0.01 0.03 0.05 0.07 0.06 0.04 0.04 0.08 0.05 0.06 0.07 0.06 0.05\n",
      " 0.03 0.02 0.02 0.05 0.01 0.02 0.02 0.02 0.03 0.01 0.01 0.   0.   0.\n",
      " 0.   0.02 0.02 0.01 0.   0.   0.   0.   0.   0.01]\n",
      "\n",
      "TotalVariation(p1,p2)=\n",
      "0.17600000000000002\n",
      "\n",
      "TotalVariation(p1,q1)=\n",
      "0.9959999999999999\n"
     ]
    }
   ],
   "source": [
    "G1=GrowingRandomGraphs(1000,0.5,2)\n",
    "G2=GrowingRandomGraphs(1000,0.5,2)\n",
    "H=InducedSubgraph(G1, n=100)\n",
    "p1=DegreeDistribution(G1)\n",
    "p2=DegreeDistribution(G2)\n",
    "q1=DegreeDistribution(H)\n",
    "print(f'p1:\\n{p1}')\n",
    "print(f'\\np2:\\n{p2}')\n",
    "print(f'\\nq1:\\n{q1}')\n",
    "print(f'\\nTotalVariation(p1,p2)=\\n{TotalVariation(p1,p2)}') #Total variation of the degree distibutions of two different copies.\n",
    "print(f'\\nTotalVariation(p1,q1)=\\n{TotalVariation(p1,q1)}')  #Total variation of the degree distrbutions of a graph and a section of it. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do you have any intuition what happened for the different choices of gamma? Run more experiments to gain more insights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The denominator grows with $k$, thus the quotient shrinks. The rate of this shrinkage can be affected by setting $M\\geq1$ to a higher number or $\\gamma\\geq1$. However, when $\\gamma\\leq1$ or ($M$ is big enough) the function will result in a number that is bigger than one, so an edge will be created with one probability at the later stages of the iteration as well. For this reason, when $M$ or $\\gamma$ are big, when we look at the graph at an early stage or a later stage, it doesn't really matter, as there will be an edge at later stages with decreasingingly small probabilities. This can be seen when we set $\\gamma=2$ compared to the case where $\\gamma=1$ ceteris paribus. Then, when we choose $\\gamma=0.5$ the total variation for the fully evolved graph versus it's early induced subgraph is almost 1. Also we could experience a significant running time increment in this case."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SageMath 9.2",
   "language": "sage",
   "name": "sagemath"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
